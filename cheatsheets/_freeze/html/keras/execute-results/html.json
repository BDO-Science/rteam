{
  "hash": "38efddf0a6b298c63a508c0079769b50",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Deep Learning with Keras :: Cheatsheet\"\ndescription: \" \"\nimage-alt: \"\"\nexecute:\n  eval: false\n  output: true\n  warning: false\n---\n\n::: {.cell .column-margin}\n<img src=\"images/logo-tensorflow.png\" height=\"138\" alt=\"Hex logo for tensorflow - A red hexagon with a stylized 'TFR' (denoting TensorFlow for R) in a lighter shade of red, with the 'F' joined to the 'R'.\" />\n<br><br><a href=\"../keras.pdf\">\n<p><i class=\"bi bi-file-pdf\"></i> Download PDF</p>\n<img src=\"../pngs/keras.png\" width=\"200\" alt=\"\"/>\n</a>\n<br><br><p>Translations (PDF)</p>\n* <a href=\"../translations/chinese/keras_zh_cn.pdf\"><i class=\"bi bi-file-pdf\"></i>Chinese</a>\n* <a href=\"../translations/japanese/keras_ja.pdf\"><i class=\"bi bi-file-pdf\"></i>Japanese</a>\n* <a href=\"../translations/spanish/keras_es.pdf\"><i class=\"bi bi-file-pdf\"></i>Spanish</a>\n:::\n\n\n\n\n## Intro\n\n**Keras** is a high-level neural networks API developed with a focus on enabling fast experimentation.\nIt supports multiple back-ends, including TensorFlow, Jax and Torch.\n\nBackends like TensorFlow are lower level mathematical libraries for building deep neural network architectures.\nThe keras3 R package makes it easy to use Keras with any backend in R.\n\n1.  **Define**: Model, Sequential model, Multi-GPU model\n2.  **Compile**: Optimizer, Loss, Metrics\n3.  **Fit**: Batch size, Epochs, Validation split\n4.  **Evaluate**: Evaluate, Plot\n5.  **Predict**: Classes, Probability\n\nRead more at:\\\n<https://keras.posit.co>\\\n<https://www.manning.com/books/deep-learning-with-r-second-edition>\n\n### Installation\n\nThe keras3 R package uses the Python keras library.\nYou can install all the prerequisites directly from R See `?keras3::install_keras` for details and options.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras3)\nreticulate::install_python()\ninstall_keras()\n```\n:::\n\n\n\n\nThis installs the required libraries in virtual environment named 'r-keras'.\nIt will automatically detect if a GPU is available.\n\n### Training an Image Recognizer on MNIST Data\n\nThe \"Hello, World!\" of deep learning\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# input layer: use MNIST images\nmnist <- dataset_mnist()\nx_train <- mnist$train$x;  y_train <- mnist$train$y\nx_test <- mnist$test$x;  y_test <- mnist$test$y\n\n# reshape and rescale\nx_train <- array_reshape(x_train, c(nrow(x_train), 784))\nx_test <- array_reshape(x_test, c(nrow(x_test), 784))\nx_train <- x_train / 255;  x_test <- x_test / 255\n\ny_train <- to_categorical(y_train, 10)\ny_test <- to_categorical(y_test, 10)\n\n# defining the model and layers\nmodel <-\n  keras_model_sequential(input_shape = c(28, 28, 1))\nmodel |>\n  layer_conv_2d(filters = 32, kernel_size = c(3, 3),\n                activation = \"relu\") |>\n  layer_max_pooling_2d(pool_size = c(2, 2)) |>\n  layer_conv_2d(filters = 64, kernel_size = c(3, 3),\n                activation = \"relu\") |>\n  layer_max_pooling_2d(pool_size = c(2, 2)) |>\n  layer_flatten() |>\n  layer_dropout(rate = 0.5) |>\n  layer_dense(units = num_classes,\n              activation = \"softmax\")\n\n# View the model summary\nsummary(model)\nplot(model)\n\n# compile (define loss and optimizer)\nmodel |> \n  compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_rmsprop(),\n  metrics = c('accuracy')\n)\n\n# train (fit)\nmodel |> fit(\n  x_train, y_train,\n  epochs = 30, batch_size = 128,\n  validation_split = 0.2\n)\nmodel |> evaluate(x_test, y_test)\nmodel |> predict(x_test)\n\n# save the full model\nsave_model(model, \"mnist-classifier.keras\")\n\n# deploy for serving inference.\ndir.create(\"serving-mnist-classifier\")\nexport_savedmodel(modek, \"serving-mnist-classifier/1\")\nrsconnect::deployTFModel(\"serving-mnist-classifier\")\n```\n:::\n\n\n\n\n## Working with Keras models\n\n### Define a Model\n\n#### Functional API: `keras_input()` and `keras_model()`\n\nDefine a Functional Model with inputs and outputs.\n\n``` r\ninputs <- keras_input(<input-shape>)\noutputs <- inputs |>\n  layer_dense() |> layer_...\nmodel <- keras_model(inputs, outputs)\n```\n\n#### Sequential API: `keras_model_sequential()`\n\nDefine a Sequential Model composed of a linear stack of layers\n\n``` r\nmodel <-\n  keras_model_sequential(<input-shape>) |>\n  layer_dense() |> layer_...\n```\n\n#### Subclassing API: `Model()`\n\nSubclass the base Model class\n\n### Compile a Model\n\n`compile(object, optimizer, loss, metrics = NULL)`: Configure a Keras model for training.\n\n### Fit a Model\n\n`fit(object, x = NULL, y = NULL, batch_size = NULL, epochs = 10, verbose = 1, callbacks = NULL, ...)`: Train a Keras model for a fixed number of epochs (iterations)\n\nCustomize training:\n\n-   Provide callbacks to `fit()`:\n-   Define a custom `Callback()`.\n-   Call `train_on_batch()` in a custom training loop.\n-   Subclass `Model()` and implement a custom `train_step` method.\n-   Write a fully custom training loop. Update weights with `model$optimizer$apply(gradients, weights)`\n\n### Inspect a Model\n\n-   `print(model)`: Print a summary of a Keras model\n\n-   `plot(model,  show_shapes = FALSE, show_dtype = FALSE, show_layer_names = FALSE, ...)`: Plot a Keras model\n\n### Evaluate a Model\n\n-   `evaluate(object, x = NULL, y = NULL, batch_size = NULL)`: Evaluate a Keras model.\n\n### Predict\n\n-   `predict()`: Generate predictions from a Keras model.\n\n-   `predict_on_batch()`: Returns predictions for a single batch of samples.\n\n### Save/Load a Model\n\n-   `save_model()`; `load_model()`: Save/Load models using the \".keras\" file format.\n\n-   `save_model_weights()`; `load_model_weights()`: Save/load model weights to/from \".h5\" files.\n\n-   `save_model_config()`; `load_model_config()`: Save/load model architecture to/from a \".json\" file.\n\n### Core Layers\n\n-   `layer_dense()`: Add a densely-connected NN layer to an output.\n\n-   `layer_einsum_dense()`: Add a dense layer with arbitrary dimensionality.\n\n-   `layer_activation()`: Apply an activation function to an output.\n\n-   `layer_dropout()`: Applies Dropout to the input.\n\n-   `layer_reshape()`: Reshapes an output to a certain shape.\n\n-   `layer_permute()`: Permute the dimensions of an input according to a given pattern.\n\n-   `layer_repeat_vector()`: Repeats the input n times.\n\n-   `layer_lambda(object, f)`: Wraps arbitrary expression as a layer.\n\n-   `layer_activity_regularization()`: Layer that applies an update to the cost function based input activity.\n\n-   `layer_masking()`: Masks a sequence by using a mask value to skip timesteps.\n\n-   `layer_flatten()`: Flattens an input.\n\n<!-- Page 2 -->\n\n## More layers\n\n### Convolutional Layers\n\n-   `layer_conv_1d()`: 1D, e.g. temporal convolution.\n\n-   `layer_conv_2d_transpose()`: Transposed 2D (deconvolution).\n\n-   `layer_conv_2d()` : 2D, e.g. spatial convolution over images.\n\n-   `layer_conv_3d_transpose()`: Transposed 3D (deconvolution).\n\n-   `layer_conv_3d()`: 3D, e.g. spatial convolution over volumes.\n\n-   `layer_conv_lstm_2d()`: Convolutional LSTM.\n\n-   `layer_separable_conv_2d()`: Depthwise separable 2D.\n\n-   `layer_upsampling_1d()`; `layer_upsampling_2d()`; `layer_upsampling_3d()`: Upsampling layer.\n\n-   `layer_zero_padding_1d()`; `layer_zero_padding_2d()`; `layer_zero_padding_3d()`: Zero-padding layer.\n\n-   `layer_cropping_1d()`; `layer_cropping_2d()`; `layer_cropping_3d()`: Cropping layer.\n\n### Pooling Layers\n\n-   `layer_max_pooling_1d()`; `layer_max_pooling_2d()`; `layer_max_pooling_3d()`: Maximum pooling for 1D to 3D.\n\n-   `layer_average_pooling_1d()`; `layer_average_pooling_2d()`; `layer_average_pooling_3d()`: Average pooling for 1D to 3D.\n\n-   `layer_global_max_pooling_1d()`; `layer_global_max_pooling_2d()`; `layer_global_max_pooling_3d()`: Global maximum pooling.\n\n-   `layer_global_average_pooling_1d()`; `layer_global_average_pooling_2d()`; `layer_global_average_pooling_3d()`: Global average pooling.\n\n## Preprocessing\n\n### Image Preprocessing\n\n#### Load Images\n\n-   `image_dataset_from_directory()` Create a TF Dataset from image files in a directory.\n\n-   `image_load()`, `image_from_array()`, `image_to_array()`,  `image_array_save()`: Work with PIL Image instances\n\n#### Transform Images\n\nOperations that transform image tensors in deterministic ways.\n\n- `op_image_crop()`\n- `op_image_extract_patches()`\n- `op_image_pad()`\n- `op_image_resize()`\n- `op_image_affine_transform()`\n- `op_image_map_coordinates()`\n- `op_image_rgb_to_grayscale()`\n\n\nResize images without aspect ratio distortion.\n\n- `image_smart_resize()`:\n\n#### Image Layers\n\nBuiltin image preprocessing layers.\nNote, any image operation function can also be used as a layer in a Model, or used in `layer_lambda()`.\n\n##### Image Preprocessing Layers\n\n- `layer_resizing()`\n- `layer_rescaling()`\n- `layer_center_crop()`\n\n##### Image Augmentation Layers\nPreprocessing layers that randomly augment image inputs during training.\n\n- `layer_random_crop()`\n- `layer_random_flip()`\n- `layer_random_translation()`\n- `layer_random_rotation()`\n- `layer_random_zoom()`\n- `layer_random_contrast()`\n- `layer_random_brightness()`\n\n### Sequence Preprocesing\n\n- `timeseries_dataset_from_array()`: Generate a TF Dataset of sliding windows over a timeseries provided as array.\n\n- `audio_dataset_from_directory()`: Generate a TF Dataset from audio files.\n\n- `pad_sequences()`: Pad sequences to the same length\n\n### Text Preprocessing\n\n- `text_dataset_from_directory()`: Generate a TF Dataset from text files in a directory.\n\n- `layer_text_vectorization()`, `get_vocabulary()`, `set_vocabulary()`: Map text to integer sequences.\n\n### Numerical Features Preprocessing\n\n- `layer_normalization()`: Normalizes continuous features.\n\n- `layer_discretization()`: Buckets continuous features by ranges.\n\n### Categorical Features Preprocessing\n\n- `layer_category_encoding()`: Encode integer features.\n\n- `layer_hashing()`: Hash and bin categorical features.\n\n- `layer_hashed_crossing()`: Cross features using the \"hashing trick\".\n\n- `layer_string_lookup()`: Map strings to (possibly encoded) indices.\n\n- `layer_integer_lookup()`: Map integers to (possibly encoded) indices.\n\n### Tabular Data\nOne-stop utility for preprocessing and encoding structured data. Define a feature space from a list of table columns (features).\n```r\nfeature_space <- layer_feature_space(features = list(<features>))\n```\n\nAdapt the feature space to a dataset\n```r\nadapt(feature_space, dataset)\n```\n\nUse the adapted `feature_space` preprocessing layer as a layer in a Keras Model, or in the data input pipeline with `tfdatasets::dataset_map()`\n\n\nAvailable features:\n\n- `feature_float()`\n- `feature_float_rescaled()`\n- `feature_float_normalized()`\n- `feature_float_discretized()`\n- `feature_integer_categorical()`\n- `feature_integer_hashed()`\n- `feature_string_categorical()`\n- `feature_string_hashed()`\n- `feature_cross()`\n- `feature_custom()`\n\n\n## Pre-trained models\n\nKeras applications are deep learning models that are made available alongside pre-trained weights.\nThese models can be used for prediction, feature extraction, and fine-tuning.\n\nMobileNetV3  Model, pre-trained on ImageNet\n\n- `application_mobilenet_v3_large()`\n- `application_mobilenet_v3_small()`\n\nEfficientNetV2 Model, pre-trained on ImageNet\n\n- `application_efficientnet_v2s()`\n- `application_efficientnet_v2m()`\n- `application_efficientnet_v2l()`\n\nInception-ResNet v2 and v3 model, with weights trained on ImageNet\n\n- `application_inception_resnet_v2()`\n- `application_inception_v3()`\n\nVGG16 and VGG19 models\n\n- `application_vgg16()`\n- `application_vgg19()`\n\nResNet50 model\n\n- `application_resnet50()`:\n\nNASNet model architecture\n\n- `application_nasnet_large()`\n- `application_nasnet_mobile()`\n\n\nImageNet is a large database of images with labels, extensively used for deep learning\n\nPreprocesses a tensor encoding a batch of images for an application, and decodes predictions from an application.\n- `application_preprocess_inputs()`\n- `application_decode_predictions()`\n\n\n## Callbacks\n\nA callback is a set of functions to be applied at given stages of the training procedure.\nYou can use callbacks to get a view on internal states and statistics of the model during training.\n\n-   `allback_early_stopping()`: Stop training when a monitored quantity has stopped improving.\n\n-   `callback_learning_rate_scheduler()`: Learning rate scheduler.\n\n-   `callback_tensorboard()`: TensorBoard basic visualizations.\n\n------------------------------------------------------------------------\n\nCC BY SA Posit Software, PBC • [info\\@posit.co](mailto:info@posit.co) • [posit.co](https://posit.co)\n\nLearn more at [keras.posit.co](https://keras.posit.co/).\n\nUpdated: 2024-06.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npackageVersion(\"keras3\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '1.0.0'\n```\n\n\n:::\n:::\n\n\n\n\n------------------------------------------------------------------------\n",
    "supporting": [
      "keras_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}